{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e616a902",
   "metadata": {},
   "source": [
    "# PyGraSPI Introduction\n",
    "\n",
    "This notebook provides an introduction to using the PyGraSPI API. PyGraSPI provides a set of features or descriptors from sample microstructures. It is an alternative to using 2-point stats in homogenization workflows for materials science AI applications. PyGraSPI currently provides a function, `make_descriptors`, that takes a set of microstructures and returns a set of descriptors in a Pandas dataframe. PyGraSPI returns two main categories of descriptors. The first is based on the graph network generated from the microstructure where the graph nodes are colored based on the material phase. This method provides descriptors such as vertex count, tortuosity and connected components. The second method, based on the skeleton of the graph, provides features concerned with the internal cycles and intersections in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c08cd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PyGraSPI Intro\n",
    "\"\"\"\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import pandas\n",
    "from pymks import solve_cahn_hilliard\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from toolz.curried import curry, pipe\n",
    "\n",
    "from pygraspi.combined_descriptors import (_make_skeletal_descriptors,\n",
    "                                           make_descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8b8e70",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "The data used here consists of 573 artificially generated microstructures from Cahn-Hilliard simulations with 401x101 shaped grids (see [Jivani et al.](https://doi.org/10.1016/j.commatsci.2021.110409) for more details). Each data sample is generated with a random initial condition and with different initial volume fractions and interaction parameters and run for varying durations. On unzipping the data in `data/cahn-hilliard.zip` there are files of the type `data_X.XXX_Y.Y_NNNNNNN.txt` where the `X.XXX` refer to the volume fraction and the `Y.Y` refer to the interaction parameter values. The `NNNNNN` denotes the number of time steps reached for that particular sample. Note that files with corresponding volume fractions and interaction parameters are from the same simulation (just with varying duration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4995fb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 401, 101)\n"
     ]
    }
   ],
   "source": [
    "@curry\n",
    "def read_data(zip_stream_, file_name):\n",
    "    \"\"\"Read a single CSV file\"\"\"\n",
    "    return np.array(\n",
    "        pandas.read_csv(\n",
    "            zip_stream_.open(file_name, \"r\"), delimiter=\" \", header=None\n",
    "        ).swapaxes(0, 1)\n",
    "    )\n",
    "\n",
    "\n",
    "with zipfile.ZipFile(\"data/cahn-hilliard.zip\", \"r\") as zip_stream:\n",
    "    data = np.array(\n",
    "        list(\n",
    "            # pylint: disable=no-value-for-parameter\n",
    "            map(read_data(zip_stream), zip_stream.namelist()[:3])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06942ad0",
   "metadata": {},
   "source": [
    "Currently, we are only using 3 samples as the implementation uses NetworkX, which is extremely slow for this category of calculations. The new implementation will use Graph-tool, which is considerably more efficient for these calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e1a11ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m make_descriptors(data)\n",
      "File \u001b[0;32m~/git/pygraspi/pygraspi/combined_descriptors.py:112\u001b[0m, in \u001b[0;36mmake_descriptors\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_descriptors\u001b[39m(data):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124;03m\"\"\"\"Generate microstructure descriptors\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m    ========================= ===========\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat([_make_skeletal_descriptors(data), \u001b[43m_make_graph_descriptors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/git/pygraspi/pygraspi/combined_descriptors.py:55\u001b[0m, in \u001b[0;36m_make_graph_descriptors\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_graph_descriptors\u001b[39m(data):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate multiple microstructure descriptors using graphs\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgetGraspiDescriptors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nix/store/kpf97qpxp10675aw0kydwf5k7ksindqy-python3.9-toolz-0.11.2/lib/python3.9/site-packages/toolz/functoolz.py:630\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(data, *funcs)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03m\"\"\" Pipe a value through a sequence of functions\u001b[39;00m\n\u001b[1;32m    611\u001b[0m \n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03mI.e. ``pipe(data, f, g, h)`` is equivalent to ``h(g(f(data)))``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m    thread_last\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[0;32m--> 630\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/git/pygraspi/pygraspi/graph_descriptors.py:226\u001b[0m, in \u001b[0;36mgetGraspiDescriptors\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    214\u001b[0m g \u001b[38;5;241m=\u001b[39m makeInterfaceEdges(g)\n\u001b[1;32m    215\u001b[0m [interface_area, phase_0_interface, phase_1_interface] \u001b[38;5;241m=\u001b[39m interfaceArea(g)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    218\u001b[0m     phase_0_count\u001b[38;5;241m=\u001b[39mcount_of_vertices(g, \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    219\u001b[0m     phase_1_count\u001b[38;5;241m=\u001b[39mcount_of_vertices(g, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    220\u001b[0m     phase_0_cc\u001b[38;5;241m=\u001b[39mmakeConnectedComponents(g, \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    221\u001b[0m     phase_1_cc\u001b[38;5;241m=\u001b[39mmakeConnectedComponents(g, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    222\u001b[0m     interfacial_area\u001b[38;5;241m=\u001b[39minterface_area,\n\u001b[1;32m    223\u001b[0m     phase_0_interface\u001b[38;5;241m=\u001b[39mphase_0_interface,\n\u001b[1;32m    224\u001b[0m     phase_1_interface\u001b[38;5;241m=\u001b[39mphase_1_interface,\n\u001b[1;32m    225\u001b[0m     distance_to_interface\u001b[38;5;241m=\u001b[39mshortest_distances_all(g),\n\u001b[0;32m--> 226\u001b[0m     distance_to_interface_0\u001b[38;5;241m=\u001b[39m\u001b[43mshortest_distances_phase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    227\u001b[0m     distance_to_interface_1\u001b[38;5;241m=\u001b[39mshortest_distances_phase(g, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    228\u001b[0m )\n",
      "File \u001b[0;32m~/git/pygraspi/pygraspi/graph_descriptors.py:181\u001b[0m, in \u001b[0;36mshortest_distances_phase\u001b[0;34m(G, phase)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03mCalculate the shortest distances to the meta vertices.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m>>> assert(shortest_distances_phase(g, 1) == 2.0)\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m source \u001b[38;5;241m=\u001b[39m [node \u001b[38;5;28;01mfor\u001b[39;00m node, data \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39mnodes(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m phase]\n\u001b[0;32m--> 181\u001b[0m path \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    182\u001b[0m     nx\u001b[38;5;241m.\u001b[39mshortest_path(G, s, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdijkstra\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m source\n\u001b[1;32m    184\u001b[0m ]\n\u001b[1;32m    185\u001b[0m path_length \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m path]\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(path_length) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(path_length)\n",
      "File \u001b[0;32m~/git/pygraspi/pygraspi/graph_descriptors.py:182\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03mCalculate the shortest distances to the meta vertices.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m>>> assert(shortest_distances_phase(g, 1) == 2.0)\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m source \u001b[38;5;241m=\u001b[39m [node \u001b[38;5;28;01mfor\u001b[39;00m node, data \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39mnodes(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m phase]\n\u001b[1;32m    181\u001b[0m path \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 182\u001b[0m     \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshortest_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdijkstra\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m source\n\u001b[1;32m    184\u001b[0m ]\n\u001b[1;32m    185\u001b[0m path_length \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m path]\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(path_length) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(path_length)\n",
      "File \u001b[0;32m/nix/store/m7s23vlgvq3ls4mh3q3ad0ynwhg2n5dn-python3.9-networkx-2.7.1/lib/python3.9/site-packages/networkx/algorithms/shortest_paths/generic.py:165\u001b[0m, in \u001b[0;36mshortest_path\u001b[0;34m(G, source, target, weight, method)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Find shortest source-target path.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 165\u001b[0m         paths \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional_shortest_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdijkstra\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    167\u001b[0m         _, paths \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mbidirectional_dijkstra(G, source, target, weight)\n",
      "File \u001b[0;32m/nix/store/m7s23vlgvq3ls4mh3q3ad0ynwhg2n5dn-python3.9-networkx-2.7.1/lib/python3.9/site-packages/networkx/algorithms/shortest_paths/unweighted.py:224\u001b[0m, in \u001b[0;36mbidirectional_shortest_path\u001b[0;34m(G, source, target)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mNodeNotFound(msg)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# call helper to do the real work\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43m_bidirectional_pred_succ\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m pred, succ, w \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# build path from pred+w+succ\u001b[39;00m\n",
      "File \u001b[0;32m/nix/store/m7s23vlgvq3ls4mh3q3ad0ynwhg2n5dn-python3.9-networkx-2.7.1/lib/python3.9/site-packages/networkx/algorithms/shortest_paths/unweighted.py:287\u001b[0m, in \u001b[0;36m_bidirectional_pred_succ\u001b[0;34m(G, source, target)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m Gpred[v]:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m succ:\n\u001b[0;32m--> 287\u001b[0m         succ[w] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m    288\u001b[0m         reverse_fringe\u001b[38;5;241m.\u001b[39mappend(w)\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m pred:  \u001b[38;5;66;03m# found path\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "make_descriptors(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb4193",
   "metadata": {},
   "source": [
    "The following demonstrates how to use the graph descriptors to classify microstructures. \n",
    "\n",
    "Here, two categories of microstructure are generated each with 96 samples using a Cahn-Hilliard simulation. The two categories of microstructures differ based on the duration of evolution (10 steps versus 100 steps). This is not a particularly useful machine learning example, but suffices to demonstrate using the graph descriptors alongside Scikit-learn.\n",
    "\n",
    "The `generate_data` function uses the PyMKS function `solve_cahn_hilliard` to generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec804ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_category, n_chunks, n_domain, seed=99):\n",
    "    \"\"\"Generate the Cahn-Hilliard data\"\"\"\n",
    "    da.random.seed(seed)\n",
    "    solve_ch = curry(solve_cahn_hilliard)(delta_t=1.0, delta_x=0.5)\n",
    "    x_data_ = pipe(\n",
    "        da.random.random(\n",
    "            (n_category * 2, n_domain, n_domain), chunks=(n_chunks, n_domain, n_domain)\n",
    "        ),\n",
    "        lambda x: 2 * x - 1,\n",
    "        lambda x: [\n",
    "            solve_ch(x[:n_category], n_steps=10),\n",
    "            solve_ch(x[n_category:], n_steps=100),\n",
    "        ],\n",
    "        da.concatenate,\n",
    "        lambda x: da.where(x > 0, 1, 0).persist(),\n",
    "    )\n",
    "    y_data_ = da.from_array(\n",
    "        np.concatenate([np.zeros(n_category), np.ones(n_category)]).astype(int),\n",
    "        chunks=(n_chunks,),\n",
    "    )\n",
    "    return np.array(x_data_), np.array(y_data_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67c101a",
   "metadata": {},
   "source": [
    "Below, `n_category` refers to the number of samples per category, `n_chunks` refers to the number of samples per chunk of data in the Dask array, `n_domain` refers to the number of pixels along an edge of the domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d5917",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = generate_data(n_category=96, n_chunks=24, n_domain=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdabff1",
   "metadata": {},
   "source": [
    "The following generates the graph descriptors from the raw microstructures. Note that only `_make_skeletal_descriptors` is used as the graph descriptors are inefficient in the current version of PyGraSPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b50b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace this with make_descriptors when switched over to use Graph-tool\n",
    "x_graph = _make_skeletal_descriptors(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906abcf2",
   "metadata": {},
   "source": [
    "The redundant, constant-value features need to be removed otherwise the `LogisticRegression` fails to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e833d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~x_graph.eq(x_graph.iloc[0]).all()\n",
    "x_graph_clean = x_graph.loc[:, mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c233b081",
   "metadata": {},
   "source": [
    "Train / test split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d30cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_graph, x_test_graph, y_train, y_test = train_test_split(\n",
    "    np.array(x_graph_clean), y_data, test_size=0.2, random_state=99\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4f46d1",
   "metadata": {},
   "source": [
    "The graph data is required to be scaled for the logistic regression. Note that the scaler is only fit using the training data (not all the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_graph)\n",
    "x_test_scaled = scaler.transform(x_test_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359e9b31",
   "metadata": {},
   "source": [
    "train ther regresson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "model = LogisticRegression().fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b52792",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03667b69",
   "metadata": {},
   "source": [
    "This is a very easy classification problem and so the predictions are perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd8d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6abf40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
